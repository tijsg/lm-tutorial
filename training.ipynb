{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaUV6-_b_Psu"
      },
      "source": [
        "# How do we make software understand language?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbIHuMB9_ade"
      },
      "source": [
        "## Analogy with language tests\n",
        "Fill in the missing word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CziGKAEV_ViM"
      },
      "source": [
        "## Encoding\n",
        "Every string is already encoded character per character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWt4GO0l-0wN",
        "outputId": "bc5790e3-28ce-467c-ff5e-e6375262a6e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UTF-8 code for char a is: 97\n",
            "UTF-8 code for char b is: 98\n",
            "UTF-8 code for char c is: 99\n",
            "UTF-8 code for char d is: 100\n",
            "UTF-8 code for char e is: 101\n",
            "UTF-8 code for char f is: 102\n",
            "UTF-8 code for char g is: 103\n",
            "UTF-8 code for char h is: 104\n",
            "UTF-8 code for char i is: 105\n",
            "UTF-8 code for char j is: 106\n",
            "UTF-8 code for char k is: 107\n",
            "UTF-8 code for char l is: 108\n",
            "UTF-8 code for char m is: 109\n",
            "UTF-8 code for char n is: 110\n",
            "UTF-8 code for char o is: 111\n",
            "UTF-8 code for char p is: 112\n",
            "UTF-8 code for char q is: 113\n",
            "UTF-8 code for char r is: 114\n",
            "UTF-8 code for char s is: 115\n",
            "UTF-8 code for char t is: 116\n",
            "UTF-8 code for char u is: 117\n",
            "UTF-8 code for char v is: 118\n",
            "UTF-8 code for char w is: 119\n",
            "UTF-8 code for char x is: 120\n",
            "UTF-8 code for char y is: 121\n",
            "UTF-8 code for char z is: 122\n"
          ]
        }
      ],
      "source": [
        "for char in (\"abcdefghijklmnopqrstuvwxyz\"):\n",
        "  print(\"UTF-8 code for char \" + char + \" is: \" + str(ord(char)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO9zLviL8faF"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBWFbYZmzoVa",
        "outputId": "55c27a72-e663-4fb4-afdc-05b05599223b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tokenizers==0.12.1\n",
            "  Downloading tokenizers-0.12.1.tar.gz (220 kB)\n",
            "     -------------------------------------- 220.7/220.7 kB 3.3 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting transformers==4.21.3\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "     ---------------------------------------- 4.7/4.7 MB 6.8 MB/s eta 0:00:00\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
            "     ---------------------------------------- 10.6/10.6 MB 8.1 MB/s eta 0:00:00\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "     -------------------------------------- 474.6/474.6 kB 9.9 MB/s eta 0:00:00\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "     ------------------------------------- 224.5/224.5 kB 13.4 MB/s eta 0:00:00\n",
            "Collecting numpy>=1.17\n",
            "  Downloading numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
            "     ---------------------------------------- 14.8/14.8 MB 9.6 MB/s eta 0:00:00\n",
            "Collecting packaging>=20.0\n",
            "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
            "     -------------------------------------- 143.2/143.2 kB 8.3 MB/s eta 0:00:00\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2023.5.5-cp311-cp311-win_amd64.whl (267 kB)\n",
            "     ------------------------------------- 267.9/267.9 kB 16.1 MB/s eta 0:00:00\n",
            "Collecting requests\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "     ---------------------------------------- 62.6/62.6 kB ? eta 0:00:00\n",
            "Collecting tqdm>=4.27\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "     ---------------------------------------- 77.1/77.1 kB ? eta 0:00:00\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "     ------------------------------------- 502.3/502.3 kB 10.5 MB/s eta 0:00:00\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "     ------------------------------------- 341.8/341.8 kB 10.7 MB/s eta 0:00:00\n",
            "Collecting pyarrow>=8.0.0\n",
            "  Downloading pyarrow-12.0.0-cp311-cp311-win_amd64.whl (21.4 MB)\n",
            "     --------------------------------------- 21.4/21.4 MB 11.5 MB/s eta 0:00:00\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "     -------------------------------------- 110.5/110.5 kB 6.3 MB/s eta 0:00:00\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp311-cp311-win_amd64.whl (30 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "     ---------------------------------------- 134.3/134.3 kB ? eta 0:00:00\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "     ------------------------------------- 160.1/160.1 kB 10.0 MB/s eta 0:00:00\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp311-cp311-win_amd64.whl (317 kB)\n",
            "     -------------------------------------- 317.2/317.2 kB 9.6 MB/s eta 0:00:00\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
            "Collecting charset-normalizer<4.0,>=2.0\n",
            "  Downloading charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
            "     ---------------------------------------- 96.7/96.7 kB 5.8 MB/s eta 0:00:00\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp311-cp311-win_amd64.whl (28 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp311-cp311-win_amd64.whl (60 kB)\n",
            "     ---------------------------------------- 60.2/60.2 kB 3.1 MB/s eta 0:00:00\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp311-cp311-win_amd64.whl (32 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting typing-extensions>=3.7.4.3\n",
            "  Using cached typing_extensions-4.6.0-py3-none-any.whl (30 kB)\n",
            "Collecting six>=1.5\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "     -------------------------------------- 123.2/123.2 kB 7.1 MB/s eta 0:00:00\n",
            "Collecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "     -------------------------------------- 157.0/157.0 kB 9.2 MB/s eta 0:00:00\n",
            "Collecting colorama\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  Building wheel for tokenizers (pyproject.toml): started\n",
            "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
            "Failed to build tokenizers\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [51 lines of output]\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      creating build\n",
            "      creating build\\lib.win-amd64-cpython-311\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\n",
            "      copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
            "      copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
            "      copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
            "      copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
            "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
            "      copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
            "      copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
            "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
            "      copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
            "      copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
            "      copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
            "      copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
            "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
            "      copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
            "      copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
            "      copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
            "      running build_ext\n",
            "      running build_rust\n",
            "      error: can't find Rust compiler\n",
            "      \n",
            "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "      \n",
            "      To update pip, run:\n",
            "      \n",
            "          pip install --upgrade pip\n",
            "      \n",
            "      and then retry package installation.\n",
            "      \n",
            "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for tokenizers\n",
            "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n",
            "\n",
            "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install tokenizers==0.12.1 transformers==4.21.3 pandas sklearn datasets\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQiIaf9YBReN"
      },
      "source": [
        "## Load in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/tijsg/lm-tutorial/main/dutch.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4YGZZlg79HfY"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2lTwwlTy8eCV"
      },
      "outputs": [],
      "source": [
        "df_dutch = pd.read_csv(\"dutch.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "gyusko8a_YWz",
        "outputId": "daabedb0-253a-4b41-e1e7-0b94423d1ecf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8acf2384-dc75-4414-bd97-e417c7740557\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Spanje is met ingang van vandaag voorzitter van de EU. De Zweedse premier Fredrik Reinfeldt heeft het stokje, formeel om middernacht, overgedragen aan zijn Spaanse collega JoseÌ Luis Rodriguez Zapatero. Spanje is het eerste land dat het roulerend voorzitterschap overneemt onder het Verdrag van Lissabon, dat op 1 december in werking is getreden. Nieuwe functies De rol van het voorzitterschap is met het in werking treden van het Verdrag van Lissabon veranderd. Voortaan zal de Belg Herman van Rompuy de vergaderingen van de Europese Raad voorzitten. Van Rompuy vertegenwoordigt de EU ook internationaal, samen met de Britse Catherine Ashton. Zij is de buitenlandminister van de EU, ook een nieuwe functie. Spanje heeft het economisch herstel hoog op de agenda van de Europese Unie gezet. Van Rompuy organiseert volgende maand een extra EU-top over de aanpak van de economische crisis. Geslaagd De Zweden mogen terugzien op een geslaagd voorzitterschap. In het afgelopen half jaar kwam het nieuwe Verdrag er, werden er topbenoemingen geregeld en de kredietcrisis bestreden. Alleen de klimaattop in Kopenhagen was een project dat minder succesvol werd afgesloten.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vijf werknemers van het omstreden Amerikaanse ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Het Oud en Nieuwfeest op het Museumplein in Am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>President Obama heeft de eerste rapporten gekr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In de hele wereld is het nieuwe jaar feestelij...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>De hoofdprijs van de oudejaarstrekking van de ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9972</th>\n",
              "      <td>Een Chinese trein heeft het snelheidsrecord ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9973</th>\n",
              "      <td>Een universiteit in de Amerikaanse staat Texas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9974</th>\n",
              "      <td>In Brussel demonstreren tienduizenden mensen v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9975</th>\n",
              "      <td>De NS wil het papieren spoorboekje afschaffen....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9976</th>\n",
              "      <td>De Europese Commissie wil zelf gaan beoordelen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9977 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8acf2384-dc75-4414-bd97-e417c7740557')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8acf2384-dc75-4414-bd97-e417c7740557 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8acf2384-dc75-4414-bd97-e417c7740557');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Spanje is met ingang van vandaag voorzitter van de EU. De Zweedse premier Fredrik Reinfeldt heeft het stokje, formeel om middernacht, overgedragen aan zijn Spaanse collega JoseÌ Luis Rodriguez Zapatero. Spanje is het eerste land dat het roulerend voorzitterschap overneemt onder het Verdrag van Lissabon, dat op 1 december in werking is getreden. Nieuwe functies De rol van het voorzitterschap is met het in werking treden van het Verdrag van Lissabon veranderd. Voortaan zal de Belg Herman van Rompuy de vergaderingen van de Europese Raad voorzitten. Van Rompuy vertegenwoordigt de EU ook internationaal, samen met de Britse Catherine Ashton. Zij is de buitenlandminister van de EU, ook een nieuwe functie. Spanje heeft het economisch herstel hoog op de agenda van de Europese Unie gezet. Van Rompuy organiseert volgende maand een extra EU-top over de aanpak van de economische crisis. Geslaagd De Zweden mogen terugzien op een geslaagd voorzitterschap. In het afgelopen half jaar kwam het nieuwe Verdrag er, werden er topbenoemingen geregeld en de kredietcrisis bestreden. Alleen de klimaattop in Kopenhagen was een project dat minder succesvol werd afgesloten. \n",
              "0     Vijf werknemers van het omstreden Amerikaanse ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "1     Het Oud en Nieuwfeest op het Museumplein in Am...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "2     President Obama heeft de eerste rapporten gekr...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "3     In de hele wereld is het nieuwe jaar feestelij...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "4     De hoofdprijs van de oudejaarstrekking van de ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "...                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "9972  Een Chinese trein heeft het snelheidsrecord ge...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "9973  Een universiteit in de Amerikaanse staat Texas...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "9974  In Brussel demonstreren tienduizenden mensen v...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "9975  De NS wil het papieren spoorboekje afschaffen....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "9976  De Europese Commissie wil zelf gaan beoordelen...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "\n",
              "[9977 rows x 1 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dutch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v5jG94wBVj3"
      },
      "source": [
        "## Split by space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x0Z5txtjzSu5"
      },
      "outputs": [],
      "source": [
        "sentence = df_dutch.iloc[0]\n",
        "sentence = sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7b5Ju7X0t0P",
        "outputId": "64422b8a-f089-4f00-dd83-7641e62f83b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Vijf',\n",
              " 'werknemers',\n",
              " 'van',\n",
              " 'het',\n",
              " 'omstreden',\n",
              " 'Amerikaanse',\n",
              " 'beveilingingsbedrijf',\n",
              " 'Blackwater',\n",
              " 'gaan',\n",
              " 'vrijuit']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence.split(\" \")[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuCBETa3BYhA"
      },
      "source": [
        "## Tokenizers \n",
        "### Byte pair encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tbYjqtYl1uz_"
      },
      "outputs": [],
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "tokenizer.train(files=\"dutch.csv\", vocab_size=1000, min_frequency=3, \n",
        "                show_progress=True,\n",
        "                special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEBsKuWR2b1z",
        "outputId": "9933b17a-d032-4ccc-d3a7-fbeae7649cb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tokenizer/vocab.json', 'tokenizer/merges.txt']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(\"tokenizer\"): os.mkdir(\"tokenizer\")\n",
        "tokenizer.save_model(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zTB9ykts26WP"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"tokenizer\", max_len=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfHf7iH02LUl",
        "outputId": "47b3cafc-b93d-463b-be36-39f570464073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vijf werknemers van het omstreden Amerikaanse beveilingingsbedrijf Blackwater gaan vrijuit voor hun \n",
            "[0, 58, 766, 733, 82, 397, 364, 284, 293, 356, 274, 300, 295, 848, 327, 600, 326, 310, 632, 468, 72, 396, 74, 354, 80, 722, 79, 91, 767, 673, 835, 343, 329, 606, 225, 2]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer.encode(sentence[:100])\n",
        "print(sentence[:100])\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WJ0lR432XER",
        "outputId": "a38a4515-9162-48d2-f8d3-9c4dc5824e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>Vijf werknemers van het omstreden Amerikaanse beveilingingsbedrijf Blackwater gaan vrijuit voor hun </s>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode([0, 58, 766, 733, 82, 397, 364, 284, 293, 356, 274, 300, 295, 848, 327, 600, 326, 310, 632, 468, 72, 396, 74, 354, 80, 722, 79, 91, 767, 673, 835, 343, 329, 606, 225, 2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXJETFvRN9Hz"
      },
      "source": [
        "## Configure RoBERTa model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDxfksumN7cN",
        "outputId": "210b1160-ed3d-41e0-a72f-6f582e109c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num parameters:  82170201\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaConfig\n",
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "# Set a configuration for our RoBERTa model\n",
        "config = RobertaConfig(\n",
        "    vocab_size=50265,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")\n",
        "# Initialize the model from a configuration without pretrained weights\n",
        "model = RobertaForMaskedLM(config=config)\n",
        "print('Num parameters: ',model.num_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RCOBikxsOD0v"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df_dutch, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAPgHc0iTXiY",
        "outputId": "b11f6765-bbf4-4708-8a56-b6067454a309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9977 7981 1996\n"
          ]
        }
      ],
      "source": [
        "print(len(df_dutch), len(df_train), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "03VtYq4hTzTK"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# Define the Data Collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1jYm_1CU4Vp",
        "outputId": "632c225b-0b87-48c0-c3a3-1e2b539f3c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTkEks7nVFJC",
        "outputId": "23c31bf4-0dbb-4644-b223-5ac37bb28ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available!\n",
            "Number of gpu's detected: 1\n",
            "Training on GPU ...\n",
            "\n",
            "\n",
            "Device name 0== Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    c = torch.cuda.device_count()\n",
        "    print(f\"CUDA is available!\\nNumber of gpu's detected: {c}\" )\n",
        "    print('Training on GPU ...\\n\\n')\n",
        "    for i in range(c):\n",
        "        print(f'Device name {i}== {torch.cuda.get_device_name(i)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5k-TQt-QjGXS"
      },
      "outputs": [],
      "source": [
        "def encode(batch):\n",
        "    return tokenizer(batch['labels'], padding=\"max_length\", truncation=True, max_length=512,return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "b39FWIwmjHJs",
        "outputId": "f0ea91ed-4b96-4342-92c1-0124d8cd3a00"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/pandas/core/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5902</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattr__</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5899 │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._info_axis._can_hold_identifiers_and_holds_name(name)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5900 │   │   </span>):                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5901 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>[name]                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5902 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">object</span>.<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getattribute__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5903 │   </span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5904 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__setattr__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, value) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5905 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'DataFrame'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'set_transform'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/pandas/core/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m5902\u001b[0m in \u001b[92m__getattr__\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5899 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m \u001b[96mself\u001b[0m._info_axis._can_hold_identifiers_and_holds_name(name)               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5900 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5901 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m[name]                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5902 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mobject\u001b[0m.\u001b[92m__getattribute__\u001b[0m(\u001b[96mself\u001b[0m, name)                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5903 \u001b[0m\u001b[2m│   \u001b[0m                                                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5904 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__setattr__\u001b[0m(\u001b[96mself\u001b[0m, name: \u001b[96mstr\u001b[0m, value) -> \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 5905 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'DataFrame'\u001b[0m object has no attribute \u001b[32m'set_transform'\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "ds_traiqs = Dataset.from_pandas(df_trai)\n",
        "df_train.set_transform(encode)\n",
        "df_test.set_transform(encode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9Ha42xPTlgC",
        "outputId": "f54da15f-ad86-458c-9296-895c04ef4ef8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "if not os.path.exists(\"models\"): os.mkdir(\"models\")\n",
        "if not os.path.exists(\"models/roberta\"): os.mkdir(\"models/roberta\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./models/roberta',\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy = 'steps',\n",
        "    num_train_epochs=1000,\n",
        "    learning_rate=1e-5,\n",
        "    lr_scheduler_type=\"constant\",\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    save_steps=2048,\n",
        "    eval_steps=2048,\n",
        "    save_total_limit=3,\n",
        "    ignore_data_skip=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True\n",
        ")\n",
        "# Create the trainer for our model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=df_train,\n",
        "    eval_dataset=df_test,\n",
        "    #prediction_loss_only=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM2u4Qf3I6fV1Tzb98e6bOr",
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
